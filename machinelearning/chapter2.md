# 머신러닝의 주요 개념

머신러닝을 알기 위해서는 주요 4가지 개념을 이해해야 합니다.

* 모델 : 데이터를 바라보는 시점과 가정
* 손실함수 : 모델의 수식화된 학습 목표
* 최적화 : 손실함수로 표현된 모델을 실제로 학습
* 모델평가 : 모델의 성능이 실제 상황에서 어떨지 추정

## 2.1 모델 : 문제를 바라보는 관점

* 모델은 머신러닝의 시작이라고도 할 수 있습니다. 모델의 정의와 분류, 좋은 모델의 특징에 대해 알아보겠습니다.

### 2.1.1 모델이란

데이터를 갖고 문석을 할 때 패턴이 있다는 믿음을 갖고 시작하게 됩니다. 수학에서는 이것을 가정이라하며, 이런 여러가지 가정을 한데 모은 것을 머신러닝에서는 모델이라 합니다.

일반적으로 머신러닝의 과정은 아래와 같습니다.

`모델정하기 -> 모델 수식화하기 -> 모델 학습하기 -> 모델 평가하기 -> (필요에 따라 처음으로)`

과정1에서 가정을 다음과 같다고 합시다.

```이 데이터에서 x와 y는 선형적인 상관관계를 가진다. 즉, 임의의 w에 대해 y = wx와 같은 관계를 가질 것이다.```

그렇다면 과정3의 가정은 다음과 같을 수 있습니다.

```데이터를 토대로 추측한 결과 y = 2x와 같은 형태를 가진다. 그러므로 w는 2이다.```

모델을 3가지로 분류 해보겠습니다.

* 간단한 모델
* 복잡한 모델
* 구조가 있는 모델

좋은 모델이란 무엇인지, 그리고 좋은 모델을 얻기 위한 `편향-분산 트레이드오프`와 `정규화`에 대해서도 알아보겠습니다.

### 2.1.2 간단한 모델

모델이 간단하다는 것은 데이터가 간단하다는 뜻입니다. 가장 간단하시만 아주 효과적인 모델로는 `선형 모델`이 있습니다. `선형 회귀`는 대표적인 선형 모델입니다.

[선형회귀, 데이터(x)로 학습된 모델(점선), 수식은 y = -5+0.4x]

![그림](images/pic2_2.jpg)

선형회귀 정의는 다음과 같습니다.

> 수식 : Y = W<sub>0</sub> + W<sub>1</sub>X<sub>1</sub> + W<sub>2</sub>X<sub>2</sub> + ...
>
> 출력값(Y)이 입력값(피처)(X<sub>1</sub>,X<sub>2</sub>, ...)에 대해 선형적인 관계

선형관계는 출력값이 입력값(피처값)들에 가중치를 곱한 값의 합(선형결합)으로 표현되는 관계입니다. 선형적인 관계는 예를 들자면 생산량(X)과 불량품 수(Y)를 들 수 있습니다. 생산량과 불량품 수는 일반적으로 양의 상관관계인 경우가 많으므로 선형 회귀 모델이 아주 적합니다.

간단한 모델의 특징

* 데이터가 복잡하지 않고 간단하게 생겼다고 가정
* 결과를 이해하기 쉬움
* 학습이 쉬움
* 가정 자체가 강력해서 모델의 표현능력에 제약이 많음

### 2.1.3 복잡한 모델

복잡한 모델은 데이터가 상대적으로 복잡하게 생겼다고 가정할 때 사용하는 모델입니다. 예를 들어 결정 트리<sup>decision tree</sup>모델을 들 수 있습니다.

![그림](images/pic2_3.jpg)

결정 트리의 정의는 다음과 같습니다.

* 트리의 한 분기점 마다 한가지 조건(보통 입력의 한 부분)을 검사하여 분기를 합니다.
* 모든 분기가 끝나는 리프노드(맨 끝의 노드)에는 결괏값이 들어 있습니다.

결정 트리의 경우 각 데이터마다 식이 포함 될 수 있습니다. 그렇다 보니 전체 데이터에 대한 가정이 적어집니다. 그러나 이 것이 단점이 될 수 있습니다.

복잡한 모델의 특징

* 데이터가 어떻게 생겼을 것이라는 가정 자체가 별로 없습니다.
* 결과를 이해하기 어려울 수도 있습니다.
* 학습이 복잡합니다.
* 한정된 데이터에서만의 변화를 그대로 학습하므로 새로운 데이터에 대해 성능이 떨어질 수 있습니다.

### 2.1.4 구조가 있는 모델

구조가 있는 모델이 위 두가지(간단한 모델, 복잡한 모델)과 별개의 모델이 아니라 어느 항목에도 속할 수 있습니다. 다만, 몇 가지 특정 상황에서 요긴하게 쓰이는 모델이 있어 따로 설명 합니다. 구조가 있는 모델은 입력과 출력의 상관 관계를 학습할 뿐만 아니라 데이터 구조 자체를 모델링 하는 조금 특이한 모델입니다. 여기서는 순차 모델<sup>sequence model</sup>과 그래프 모델<sup>graphical model</sup>에 대해 다루겠습니다.

#### 2.1.4.1 순차 모델

순차 모델은 연속된 관측값이 서로 연관성이 있을 때 주로 사용합니다. 순차 모델의 대표적인 예는 아래 두가지 입니다.

* CRF<sup>conditional random field</sup>, (조건부 랜덤필드 또는 조건부 무작위장)
* RNN<sup>recurrent neural net</sup>, (순환신경망 또는 재귀신경망)

이들 모델의 특징은 특정 시점에서 상태를 저장하고 상태가 각 시점의 입력과 출력에 따라 변화한다는 점입니다.

RNN에 대해 알아봅시다.

![그림](images/pic2_4.png)

RNN의 기본적인 정의는 아래와 같습니다.

* 수식: h<sub>t</sub> = w<sub>0</sub> + w<sub>1</sub>h<sub>t-1</sub> + 
w<sub>2</sub>x<sub>t</sub>
* 실제로 관측되지는 않았지만 특정 시점에 어떤 상태 h<sub>t</sub>가 존재한다고 가정합시다.
* 현재의 상태(h<sub>t</sub>)는 바로 직전의 상태(h<sub>t-1</sub>)와 현재의 입력 데이터 (x<sub>t</sub>)에 영향을 받습니다.
* 상태(h<sub>t</sub>)에 따라 출력(y<sub>t</sub>)이 결정됩니다.

RNN은 상탯값이 다른 모델과의 차이점 입니다.

#### 2.1.4.2 그래프 모델

그래프 모델은 그래프를 이용해서 순차 모델 보다 좀 더 복잡한 구조를 모델링 합니다. 예를 들면 문서의 문법구조를 직접 모델링하거나 이미지의 픽셀 사이의 관계를 네트워크로 보고 그래프로 표현하여 모델링 합니다. 대표적인 마르코프 랜덤 필드<sup>markov random field</sup>(MRF)를 살펴보겠습니다.

